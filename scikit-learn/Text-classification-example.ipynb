{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn example on text classification\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's load data\n",
    "The data is from newspapers articles and they have around 20 labels\n",
    "Every file is an article and they are saved in their folder with the name of the label (Category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exmining the function we can see that we can pass a list to pull specific categories so we dont overload the computer. I will select the sugested labels on the exercise to keep up with the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_20newsgroups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    }
   ],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'description', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(twenty_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to get a good understanding on what that data is and looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: 1\n",
      "target_names: comp.graphics\n",
      "filenames: /Users/races/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38479\n"
     ]
    }
   ],
   "source": [
    "print('target: ' + str(twenty_train.target[0]) + \n",
    "      '\\ntarget_names: ' + str(twenty_train.target_names[twenty_train.target[0]]) + \n",
    "      '\\nfilenames: ' + str(twenty_train.filenames[twenty_train.target[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to tokenize all the words in the documents using bag of words that come with scikit-lear. This matrix is highly sparse given each position represent a unique word\n",
    "\n",
    "The way it works is by creating a tranformer object >> training it >> applying it to dataset \n",
    "Of course this would mean that we need to apply the same transformer to the test set of any other set (or record) that will be scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35788"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will return the position of any word from the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should nornmalize the data as some documents are bigger than others. Let's look at the frequency of words per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvIAAAH0CAYAAABfKsnMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJAHAIAOCfIAANAhQR4AADr0/wPyGMXt/88OrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113a63550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_size = [len(x) for x in twenty_train.data]\n",
    "hist_plt = plt.hist(docs_size, bins = 100, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf\n",
    "\n",
    "We can see the data is highly skewed. So what we can do is to use word frequency instead of word count. **tf** stands for Term Frequency, it divides the occurrences of each words by the total number of words in the document. Another process usually used in word-document tokenization is **th-idf** which stands for Term Frequency Inverse Document Frequency which downscale the importance of words appearing in many documents that might not really have a special weight on clasifying a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did before, we need to create a transformer object with fit_transform.\n",
    "\n",
    "Notice shape did not change as the change should be seen within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': False, 'use_idf': True}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "071 : 2 : 0.25612026239119895\n",
      "0hb : 1 : 0.1348710554299733\n",
      "14 : 1 : 0.05966162012870271\n",
      "477 : 2 : 0.24645540709354397\n",
      "8000 : 1 : 0.10783602957370853\n",
      "8565 : 1 : 0.1348710554299733\n",
      "ac : 2 : 0.12491817585060791\n",
      "advance : 1 : 0.0686611288079694\n",
      "also : 1 : 0.03900412426100995\n",
      "any : 1 : 0.0310951485922154\n",
      "anyone : 1 : 0.04316199700711876\n",
      "application : 1 : 0.08413454409085573\n",
      "city : 4 : 0.314400065528974\n",
      "collier : 3 : 0.3841803935867984\n",
      "computer : 1 : 0.049671845493333165\n",
      "convert : 1 : 0.07830787326179856\n",
      "converting : 2 : 0.21567205914741705\n",
      "correct : 1 : 0.06350565647195339\n",
      "do : 1 : 0.031042954435189937\n",
      "does : 1 : 0.037793189755988436\n",
      "ec1v : 1 : 0.1348710554299733\n",
      "email : 2 : 0.125601499991304\n",
      "fax : 1 : 0.06666452137859726\n",
      "files : 2 : 0.13635772403701527\n",
      "format : 1 : 0.07691883385947053\n",
      "from : 1 : 0.016797806021219684\n",
      "good : 1 : 0.042703686357211466\n",
      "group : 1 : 0.05417404179868691\n",
      "hampton : 1 : 0.11382738609462074\n",
      "host : 1 : 0.0360441471878483\n",
      "hp : 2 : 0.17358472047671197\n",
      "hpgl : 1 : 0.12322770354677198\n",
      "iii : 2 : 0.18626015109199115\n",
      "images : 1 : 0.0744441018788533\n",
      "img : 1 : 0.12322770354677198\n",
      "in : 1 : 0.01894546434959984\n",
      "into : 1 : 0.04525255408845407\n",
      "is : 1 : 0.019964881751854364\n",
      "know : 1 : 0.034782593244413566\n",
      "laserjet : 2 : 0.24645540709354397\n",
      "like : 1 : 0.035904358813682244\n",
      "lines : 1 : 0.016864892977128034\n",
      "london : 1 : 0.10960585507802437\n",
      "michael : 3 : 0.1962279892331408\n",
      "nntp : 1 : 0.036374916362300114\n",
      "of : 1 : 0.018249940796073682\n",
      "organization : 1 : 0.017762318563562172\n",
      "pc : 1 : 0.07802072428618635\n",
      "pd : 1 : 0.09796250319482307\n",
      "please : 1 : 0.04935883383975408\n",
      "plotter : 1 : 0.11947938145690981\n",
      "posting : 1 : 0.034290706362898604\n",
      "programmer : 1 : 0.08497460943470851\n",
      "response : 1 : 0.06899050810672397\n",
      "same : 1 : 0.047271576160535234\n",
      "sd345 : 1 : 0.1348710554299733\n",
      "standard : 1 : 0.0686611288079694\n",
      "subject : 1 : 0.016797806021219684\n",
      "tel : 1 : 0.08631915131162177\n",
      "tga : 1 : 0.10218403421141944\n",
      "thanks : 1 : 0.04910237380446671\n",
      "the : 5 : 0.08865416253721688\n",
      "this : 1 : 0.023871142738151236\n",
      "tif : 1 : 0.12806013119559947\n",
      "to : 4 : 0.07283773941616518\n",
      "uk : 2 : 0.11819702490105698\n",
      "unit : 1 : 0.09313007554599557\n",
      "university : 2 : 0.06567578043186388\n",
      "utility : 1 : 0.0999409997803694\n",
      "way : 1 : 0.043341654399042764\n",
      "we : 1 : 0.034481472140846715\n",
      "would : 1 : 0.0312703097833574\n",
      "x3769 : 1 : 0.1348710554299733\n"
     ]
    }
   ],
   "source": [
    "# Take a look ah how the words got transformed\n",
    "count_list = X_train_counts.todense()[0].tolist()\n",
    "transformed_list = X_train_tfidf.todense()[0].tolist()\n",
    "for i, (count, t_count) in enumerate(zip(count_list[0], transformed_list[0])):\n",
    "    if count > 0:\n",
    "        print(count_vect.get_feature_names()[i] + ' : ' + str(count) + ' : ' + str(t_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as reminder, this is the document\n",
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tfidf.todense()[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we have to create a classifier for our vectorized words. We will be using aaive - Bayes multinomial\n",
    "For more information, please check documentation: http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n",
    "As mentioned in documentation, naives_bayes tends to be a classifer but a really bad estimator. So, do **NOT** take too seriously the estimation of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we need to use the same tranformer created above **tfidf_transformer** but only with transfor as the vector / mapping was already trained from all the first documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building a Pipeline\n",
    "scikit learn bring a pipeline object that let us do all in a single line. For instance, all we did above coud be translated to vectorizer >> tranformer >> classifier. See, how easy is to do with pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply to our data easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information about the pipeline object details could be pulled\n",
    "text_clf.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test accuracy in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83488681757656458"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the twenty_test object was pulled at the beginning of this document\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "# predicted == twenty_test.target will be 1 for match and 0 for non-matched. numpy mean will return average\n",
    "np.mean(predicted == twenty_test.target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Support Vector Machine ** http://scikit-learn.org/stable/modules/svm.html#svm\n",
    "\n",
    "** With Stocastic Gradient Descent ** http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGDClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                    ])\n",
    "_ = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underscore (_) means previous output. So in this case it just mthe same as text_clf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn Metrics\n",
    "A more through metric output could be achieve by using metrics from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "           avg / total       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "        target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258  11  15  35]\n",
      " [  4 379   3   3]\n",
      " [  5  33 355   3]\n",
      " [  5  10   4 379]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Grid Search for Parameter Tuning\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': (0.01, 0.001),\n",
       " 'tfidf__use_idf': (True, False),\n",
       " 'vect__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using n_jobs = -1 will detect how many cores are available and use them all. By default, only 1 is used but since grid search is so expensive, it's usually recommended to use all the cores availables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "# gs_clf = gs_clf.fit(twenty_train.data[:1000], twenty_train.target[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting a value\n",
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected parameters\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96544085068675234"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best scores\n",
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1.28004424,  4.57974402,  1.16929062,  4.81641507,  1.38312157,\n",
       "         7.21937847,  1.97726496,  5.93313138]),\n",
       " 'mean_score_time': array([ 0.54371667,  1.42138028,  0.52358071,  1.47971567,  0.6774567 ,\n",
       "         2.06567589,  0.98832432,  1.5481627 ]),\n",
       " 'mean_test_score': array([ 0.90429774,  0.92113425,  0.81302614,  0.83562251,  0.96544085,\n",
       "         0.95968099,  0.92157732,  0.9308817 ]),\n",
       " 'mean_train_score': array([ 0.94882792,  0.97806822,  0.86131773,  0.88147852,  0.99822783,\n",
       "         0.99889243,  0.97230728,  0.98515748]),\n",
       " 'param_clf__alpha': masked_array(data = [0.01 0.01 0.01 0.01 0.001 0.001 0.001 0.001],\n",
       "              mask = [False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_tfidf__use_idf': masked_array(data = [True True False False True True False False],\n",
       "              mask = [False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_vect__ngram_range': masked_array(data = [(1, 1) (1, 2) (1, 1) (1, 2) (1, 1) (1, 2) (1, 1) (1, 2)],\n",
       "              mask = [False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'clf__alpha': 0.01,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}),\n",
       " 'rank_test_score': array([6, 5, 8, 7, 1, 2, 4, 3], dtype=int32),\n",
       " 'split0_test_score': array([ 0.9123506 ,  0.9309429 ,  0.83665339,  0.86719788,  0.96547145,\n",
       "         0.96281541,  0.92430279,  0.93492696]),\n",
       " 'split0_train_score': array([ 0.95079787,  0.97672872,  0.86901596,  0.89029255,  0.99800532,\n",
       "         0.99867021,  0.97340426,  0.98670213]),\n",
       " 'split1_test_score': array([ 0.90039841,  0.92828685,  0.80345286,  0.81938911,  0.96945551,\n",
       "         0.96547145,  0.91766268,  0.92828685]),\n",
       " 'split1_train_score': array([ 0.95146277,  0.9793883 ,  0.84773936,  0.86968085,  0.99867021,\n",
       "         0.99933511,  0.96875   ,  0.98404255]),\n",
       " 'split2_test_score': array([ 0.90013316,  0.90412783,  0.79893475,  0.82023968,  0.96138482,\n",
       "         0.95073236,  0.92276964,  0.92942743]),\n",
       " 'split2_train_score': array([ 0.94422311,  0.97808765,  0.86719788,  0.88446215,  0.99800797,\n",
       "         0.99867198,  0.9747676 ,  0.98472776]),\n",
       " 'std_fit_time': array([ 0.02706425,  0.07967479,  0.03152382,  0.12637968,  0.20978118,\n",
       "         0.18098817,  0.36155876,  0.34836064]),\n",
       " 'std_score_time': array([ 0.01605653,  0.05697292,  0.01738396,  0.09046833,  0.11486968,\n",
       "         0.16478464,  0.23360482,  0.47972022]),\n",
       " 'std_test_score': array([ 0.00569904,  0.01205827,  0.01681949,  0.02234469,  0.00329418,\n",
       "         0.00641167,  0.00283971,  0.00289994]),\n",
       " 'std_train_score': array([ 0.00326739,  0.00108585,  0.00963   ,  0.00867514,  0.00031281,\n",
       "         0.00031302,  0.00257622,  0.00112748])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comprehensive results of the grid search\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.280044</td>\n",
       "      <td>0.543717</td>\n",
       "      <td>0.904298</td>\n",
       "      <td>0.948828</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': True, '...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.912351</td>\n",
       "      <td>0.950798</td>\n",
       "      <td>0.900398</td>\n",
       "      <td>0.951463</td>\n",
       "      <td>0.900133</td>\n",
       "      <td>0.944223</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.003267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.579744</td>\n",
       "      <td>1.421380</td>\n",
       "      <td>0.921134</td>\n",
       "      <td>0.978068</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': True, '...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>0.976729</td>\n",
       "      <td>0.928287</td>\n",
       "      <td>0.979388</td>\n",
       "      <td>0.904128</td>\n",
       "      <td>0.978088</td>\n",
       "      <td>0.079675</td>\n",
       "      <td>0.056973</td>\n",
       "      <td>0.012058</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.169291</td>\n",
       "      <td>0.523581</td>\n",
       "      <td>0.813026</td>\n",
       "      <td>0.861318</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': False, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.836653</td>\n",
       "      <td>0.869016</td>\n",
       "      <td>0.803453</td>\n",
       "      <td>0.847739</td>\n",
       "      <td>0.798935</td>\n",
       "      <td>0.867198</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>0.016819</td>\n",
       "      <td>0.009630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.816415</td>\n",
       "      <td>1.479716</td>\n",
       "      <td>0.835623</td>\n",
       "      <td>0.881479</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': False, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.867198</td>\n",
       "      <td>0.890293</td>\n",
       "      <td>0.819389</td>\n",
       "      <td>0.869681</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.884462</td>\n",
       "      <td>0.126380</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>0.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.383122</td>\n",
       "      <td>0.677457</td>\n",
       "      <td>0.965441</td>\n",
       "      <td>0.998228</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965471</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>0.969456</td>\n",
       "      <td>0.998670</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>0.998008</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.219378</td>\n",
       "      <td>2.065676</td>\n",
       "      <td>0.959681</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': True, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.962815</td>\n",
       "      <td>0.998670</td>\n",
       "      <td>0.965471</td>\n",
       "      <td>0.999335</td>\n",
       "      <td>0.950732</td>\n",
       "      <td>0.998672</td>\n",
       "      <td>0.180988</td>\n",
       "      <td>0.164785</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.977265</td>\n",
       "      <td>0.988324</td>\n",
       "      <td>0.921577</td>\n",
       "      <td>0.972307</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': False,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924303</td>\n",
       "      <td>0.973404</td>\n",
       "      <td>0.917663</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.922770</td>\n",
       "      <td>0.974768</td>\n",
       "      <td>0.361559</td>\n",
       "      <td>0.233605</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.002576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.933131</td>\n",
       "      <td>1.548163</td>\n",
       "      <td>0.930882</td>\n",
       "      <td>0.985157</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': False,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934927</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.928287</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.929427</td>\n",
       "      <td>0.984728</td>\n",
       "      <td>0.348361</td>\n",
       "      <td>0.479720</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.280044         0.543717         0.904298          0.948828   \n",
       "1       4.579744         1.421380         0.921134          0.978068   \n",
       "2       1.169291         0.523581         0.813026          0.861318   \n",
       "3       4.816415         1.479716         0.835623          0.881479   \n",
       "4       1.383122         0.677457         0.965441          0.998228   \n",
       "5       7.219378         2.065676         0.959681          0.998892   \n",
       "6       1.977265         0.988324         0.921577          0.972307   \n",
       "7       5.933131         1.548163         0.930882          0.985157   \n",
       "\n",
       "  param_clf__alpha param_tfidf__use_idf param_vect__ngram_range  \\\n",
       "0             0.01                 True                  (1, 1)   \n",
       "1             0.01                 True                  (1, 2)   \n",
       "2             0.01                False                  (1, 1)   \n",
       "3             0.01                False                  (1, 2)   \n",
       "4            0.001                 True                  (1, 1)   \n",
       "5            0.001                 True                  (1, 2)   \n",
       "6            0.001                False                  (1, 1)   \n",
       "7            0.001                False                  (1, 2)   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'clf__alpha': 0.01, 'tfidf__use_idf': True, '...                6   \n",
       "1  {'clf__alpha': 0.01, 'tfidf__use_idf': True, '...                5   \n",
       "2  {'clf__alpha': 0.01, 'tfidf__use_idf': False, ...                8   \n",
       "3  {'clf__alpha': 0.01, 'tfidf__use_idf': False, ...                7   \n",
       "4  {'clf__alpha': 0.001, 'tfidf__use_idf': True, ...                1   \n",
       "5  {'clf__alpha': 0.001, 'tfidf__use_idf': True, ...                2   \n",
       "6  {'clf__alpha': 0.001, 'tfidf__use_idf': False,...                4   \n",
       "7  {'clf__alpha': 0.001, 'tfidf__use_idf': False,...                3   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.912351            0.950798           0.900398   \n",
       "1           0.930943            0.976729           0.928287   \n",
       "2           0.836653            0.869016           0.803453   \n",
       "3           0.867198            0.890293           0.819389   \n",
       "4           0.965471            0.998005           0.969456   \n",
       "5           0.962815            0.998670           0.965471   \n",
       "6           0.924303            0.973404           0.917663   \n",
       "7           0.934927            0.986702           0.928287   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.951463           0.900133            0.944223      0.027064   \n",
       "1            0.979388           0.904128            0.978088      0.079675   \n",
       "2            0.847739           0.798935            0.867198      0.031524   \n",
       "3            0.869681           0.820240            0.884462      0.126380   \n",
       "4            0.998670           0.961385            0.998008      0.209781   \n",
       "5            0.999335           0.950732            0.998672      0.180988   \n",
       "6            0.968750           0.922770            0.974768      0.361559   \n",
       "7            0.984043           0.929427            0.984728      0.348361   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.016057        0.005699         0.003267  \n",
       "1        0.056973        0.012058         0.001086  \n",
       "2        0.017384        0.016819         0.009630  \n",
       "3        0.090468        0.022345         0.008675  \n",
       "4        0.114870        0.003294         0.000313  \n",
       "5        0.164785        0.006412         0.000313  \n",
       "6        0.233605        0.002840         0.002576  \n",
       "7        0.479720        0.002900         0.001127  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or using pandas\n",
    "import pandas as pd \n",
    "gs_results = pd.DataFrame(gs_clf.cv_results_)\n",
    "gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
