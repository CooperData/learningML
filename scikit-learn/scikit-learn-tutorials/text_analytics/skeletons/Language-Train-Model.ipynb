{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Language Train Model\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to clone the scikit learn if you dont have the doc folder in sklearn folder within your installed packages. Navigate to doc/tutorials/text_analytics/data and run the fetch data in each tutiral you are working on. If running jupyter from skeletons, you would run the following after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_data_folder = '../data/languages/paragraphs'\n",
    "dataset = load_files(languages_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset in training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                          dataset.target, \n",
    "                                                          test_size=0.5, \n",
    "                                                          random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 10,  1,  7,  4,  2,  0,  7,  8,  9,  1,  2,  3,  5,  1,  1,\n",
       "        5,  4,  1,  5,  5,  2,  3,  2,  1,  4,  4,  4,  3, 10,  1,  4,  4,\n",
       "        9,  6,  4,  7,  2,  1,  1,  0,  2,  8,  2,  8,  8,  5,  2,  4,  2,\n",
       "        3,  2,  1,  1,  9,  7,  1,  2,  1,  6,  2,  4,  1,  6,  4,  2,  3,\n",
       "        1,  8, 10,  1, 10, 10,  3,  6,  5, 10,  8, 10,  1,  5,  6,  2,  9,\n",
       "        3,  9, 10,  4, 10, 10,  3,  3,  1,  5,  5,  5,  9,  8,  2, 10,  1,\n",
       "        3,  5,  6,  1,  0,  6,  2,  9, 10,  6,  2,  7,  1,  2,  4,  2,  5,\n",
       "        3,  2,  0,  3,  4,  5,  9,  2,  5,  7,  9,  4, 10,  1,  2,  6,  3,\n",
       "        2,  2,  0,  1,  2,  7,  9,  3, 10,  8,  3,  1,  2,  6,  1,  1,  2,\n",
       "        3,  8,  2, 10,  3,  6,  3,  9, 10,  4,  1,  6,  2,  4,  3,  5,  9,\n",
       "        2,  3,  1,  7,  6,  5,  3,  1,  9,  9,  7,  9,  1,  9,  2,  1,  9,\n",
       "        1,  9, 10,  9,  3,  3,  2, 10, 10,  4,  6,  4, 10, 10,  3,  4,  8,\n",
       "        2,  4,  6,  7,  1,  4,  1,  4,  3,  4,  5,  9,  1,  9,  2,  4,  0,\n",
       "        9,  5,  3,  5,  4, 10,  4,  4,  1,  2,  2,  1,  1,  6,  8,  1,  3,\n",
       "       10,  7,  1,  1,  1,  2,  2,  1, 10,  9,  4,  3,  6,  2,  5,  1,  6,\n",
       "        3,  8,  4,  6,  9,  3,  2,  0,  9,  1,  1,  9,  1,  2,  1,  1,  3,\n",
       "        3,  6,  3,  0,  1,  6,  4,  4,  9,  3,  5,  4,  4,  9,  8,  2,  2,\n",
       "        5,  1,  4,  1,  6, 10,  8,  5,  2,  1,  8, 10,  1,  9,  4,  2,  9,\n",
       "        5, 10,  2,  9,  2,  0, 10,  7,  3,  1,  9,  3,  6, 10,  2,  2,  7,\n",
       "        4,  1,  2,  9,  4,  2,  9,  0,  5,  6,  9,  2,  3,  4,  6,  4,  1,\n",
       "        1,  1,  8,  0,  2,  9,  2,  5, 10,  5,  4,  9,  7,  1,  4,  1,  4,\n",
       "        9,  9,  9,  3,  1, 10,  1,  4,  5,  3,  8,  2,  5,  2,  7,  7,  3,\n",
       "        9,  5,  6,  9,  4,  7,  2,  1,  9,  3,  2, 10,  9,  4,  0,  2, 10,\n",
       "        2,  1,  3,  5,  1,  4,  1,  9,  2,  1, 10,  2,  9,  2,  4,  1,  3,\n",
       "        6,  2,  3,  9,  5,  1,  9,  5,  7,  6,  0,  2,  4, 10,  3,  6,  6,\n",
       "        3,  4, 10,  2,  8,  7,  3,  9, 10,  1,  6,  1,  1,  3, 10,  6,  1,\n",
       "        4,  5,  1,  3,  3,  9,  4,  4,  6,  7,  3,  6,  3,  2,  8,  2,  9,\n",
       "        1,  5,  4,  9,  6, 10,  4,  2,  2,  3,  1,  9,  3,  9,  1,  6,  3,\n",
       "        4,  1,  2,  4,  4,  5,  9,  2,  2,  4,  2,  0,  3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer that splits strings into sequence of 1 to 3\n",
    "# characters instead of word tokens\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (1,3), use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer / classifier pipeline using the previous analyzer\n",
    "# the pipeline instance should stored in a variable named clf\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                    ('vec', tfidf_vectorizer),\n",
    "                    ('clf', Perceptron()),\n",
    "                    ])\n",
    "\n",
    "\n",
    "text_clf_MNB = Pipeline([\n",
    "                    ('vec', tfidf_vectorizer),\n",
    "                    ('clf_MNB', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Fit the pipeline on the training set\n",
    "clf = text_clf.fit(docs_train, y_train)\n",
    "clf_MNB = text_clf_MNB.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = text_clf.predict(docs_test)\n",
    "y_predicted_MNB = text_clf_MNB.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       1.00      1.00      1.00        13\n",
      "         de       1.00      1.00      1.00        74\n",
      "         en       0.99      1.00      0.99        75\n",
      "         es       1.00      0.95      0.97        61\n",
      "         fr       1.00      1.00      1.00        64\n",
      "         it       1.00      1.00      1.00        45\n",
      "         ja       1.00      1.00      1.00        36\n",
      "         nl       0.96      1.00      0.98        23\n",
      "         pl       1.00      0.96      0.98        24\n",
      "         pt       0.96      0.98      0.97        47\n",
      "         ru       0.97      1.00      0.98        28\n",
      "\n",
      "avg / total       0.99      0.99      0.99       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       0.00      0.00      0.00        13\n",
      "         de       0.22      1.00      0.37        74\n",
      "         en       0.78      1.00      0.88        75\n",
      "         es       0.00      0.00      0.00        61\n",
      "         fr       0.00      0.00      0.00        64\n",
      "         it       0.00      0.00      0.00        45\n",
      "         ja       1.00      1.00      1.00        36\n",
      "         nl       0.00      0.00      0.00        23\n",
      "         pl       0.00      0.00      0.00        24\n",
      "         pt       0.00      0.00      0.00        47\n",
      "         ru       1.00      0.96      0.98        28\n",
      "\n",
      "avg / total       0.28      0.43      0.32       490\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/races/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_predicted_MNB,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 74  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 75  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 58  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 36  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 23  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 23  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 46  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC2lJREFUeJzt3WGo5XWdx/H3Z2eSGts1xZCckR0fmIsEi+1l1xJicVxw\nt8geLK2B4YYwsOyWiRC2T6Z51oOSerAIF7WExIhJSGJxEytiYZG9jkLqtGtY6ejYzBJpNIENfffB\nPX4Zp5nmev//e///K+8XyD3nzJ/f+eLV9/zPuf/zu6kqJAngj6YeQNJ8GARJzSBIagZBUjMIkppB\nkNRmF4Qk1yX5nyQ/TnL71POcLMklSb6X5OkkTyW5ZeqZziTJtiSPJ/n21LOcKsk7khxI8qMkh5K8\nb+qZTpXk1sX3+Mkk9yd56wxmuifJ0SRPnvTYBUkeTvLM4uv5Q55jVkFIsg34N+BvgSuAjyW5Ytqp\nXucEcFtVXQFcBfzzzOY72S3AoamHOIMvAw9V1Z8Bf87M5kyyE/gUsFRV7wG2ATdMOxUAXwWuO+Wx\n24FHquoy4JHF/XWbVRCAvwR+XFXPVtWrwNeB6yeeqVXVkao6uLj9K1b/Q9457VS/L8ku4IPAXVPP\ncqok5wEfAO4GqKpXq+qX0051WtuBtyXZDuwAXpx4HqrqB8AvTnn4euDexe17gY8MeY65BWEn8PxJ\n9w8zw//hAJLsBq4EHp12ktP6EvAZ4HdTD3IalwLHgK8sXtLcleTcqYc6WVW9AHwBeA44ArxcVd+Z\ndqozuqiqjixuvwRcNGSxuQVhS0jyduCbwKer6pWp5zlZkg8BR6vqsalnOYPtwHuBO6vqSuDXDDzN\nHdvidfj1rMbrYuDcJDdOO9XZ1ernEAZ9FmFuQXgBuOSk+7sWj81GkrewGoP7quqBqec5jauBDyf5\nKasvua5J8rVpR3qdw8DhqnrtzOoAq4GYk2uBn1TVsar6LfAA8P6JZzqTnyd5F8Di69Ehi80tCP8N\nXJbk0iTnsPpGzoMTz9SShNXXvoeq6o6p5zmdqvpsVe2qqt2s/vv7blXN5m+3qnoJeD7J5YuH9gBP\nTzjS6TwHXJVkx+J7voeZvfF5kgeBmxa3bwK+NWSx7YPHGVFVnUjyL8B/sPrO7j1V9dTEY53sauDj\nwA+TPLF47F+r6t8nnGkr+iRw3yL6zwKfmHie16mqR5McAA6y+pOlx4HlaaeCJPcDfw1cmOQwsA/4\nPPCNJDcDPwM+Oug5/PizpNfM7SWDpAkZBEnNIEhqBkFSMwiS2iyDkGTv1DOczdxnnPt8MP8Z5z4f\njD/jLIMAzP4bwfxnnPt8MP8Z5z4fjDzjXIMgaQKbemFStl9YnLP77AeeOAbb33n2434z5SdSj7P6\nqdi5mvt8MP8Z5z4frH3GX1J1PGc7anMvXT5nN1y+Mt56T3xuvLWkN7W1XXntSwZJzSBIagZBUjMI\nktqgIMx5y3RJb9y6g7AFtkyX9AYNOUOY9Zbpkt64IUHYMlumS1qbDX9TMcneJCtJVjhxbKOfTtIA\nQ4Kwpi3Tq2q5qpaqamlNlyNLmsyQIMx6y3RJb9y6P8uwBbZMl/QGDfpw0+L3Efg7CaQ3Ca9UlNQM\ngqRmECQ1gyCpbe6OSb95cdRdjr7I/tHWes1t7Bt9TWmr8AxBUjMIkppBkNQMgqRmECQ1gyCpGQRJ\nzSBIagZBUjMIkppBkNQMgqRmECQ1gyCpGQRJzSBIagZBUjMIkppBkNQMgqS2uZusjmwjNkTdN/LG\nrfvdtFVbiGcIkppBkNQMgqRmECQ1gyCpGQRJbd1BSHJJku8leTrJU0luGXMwSZtvyHUIJ4Dbqupg\nkj8GHkvycFU9PdJskjbZus8QqupIVR1c3P4VcAjYOdZgkjbfKO8hJNkNXAk8OsZ6kqYx+NLlJG8H\nvgl8uqpeOc2f7wX2rt47b+jTSdpAg84QkryF1RjcV1UPnO6YqlquqqWqWoIdQ55O0gYb8lOGAHcD\nh6rqjvFGkjSVIWcIVwMfB65J8sTin78baS5JE1j3ewhV9Z9ARpxF0sS8UlFSMwiSmkGQ1AyCpLal\n91TcCPv54qjr1f7bRl0v+9yjcZ424qr9FzZgzT/MMwRJzSBIagZBUjMIkppBkNQMgqRmECQ1gyCp\nGQRJzSBIagZBUjMIkppBkNQMgqRmECQ1gyCpGQRJzSBIagZBUktVbd6T5eLq3/uqdaml/aOvmRX3\naXzzW6bqxbP+YiXPECQ1gyCpGQRJzSBIagZBUjMIkppBkNQGByHJtiSPJ/n2GANJms4YZwi3AIdG\nWEfSxAYFIcku4IPAXeOMI2lKQ88QvgR8BvjdmQ5IsjfJSpIVOD7w6SRtpHUHIcmHgKNV9dgfOq6q\nlqtqqaqWYMd6n07SJhhyhnA18OEkPwW+DlyT5GujTCVpEusOQlV9tqp2VdVu4Abgu1V142iTSdp0\nXocgqW0fY5Gq+j7w/THWkjQdzxAkNYMgqRkESc0gSGqjvKmozbMRG6I+Vt8Ydb2/yEdHXU+bxzME\nSc0gSGoGQVIzCJKaQZDUDIKkZhAkNYMgqRkESc0gSGoGQVIzCJKaQZDUDIKkZhAkNYMgqRkESc0g\nSGoGQVJzT0WNvgfiP9WfjLoewJ15ZfQ19fs8Q5DUDIKkZhAkNYMgqRkESc0gSGqDgpDkHUkOJPlR\nkkNJ3jfWYJI239DrEL4MPFRVf5/kHGDHCDNJmsi6g5DkPOADwD8CVNWrwKvjjCVpCkNeMlwKHAO+\nkuTxJHclOXekuSRNYEgQtgPvBe6sqiuBXwO3n3pQkr1JVpKswPEBTydpow0JwmHgcFU9urh/gNVA\nvE5VLVfVUlUt+RaDNG/rDkJVvQQ8n+TyxUN7gKdHmUrSJIb+lOGTwH2LnzA8C3xi+EiSpjIoCFX1\nBLA00iySJuaVipKaQZDUDIKkZhAkNYMgqbnJqka3IRuiPvS5cde7buT13iQ8Q5DUDIKkZhAkNYMg\nqRkESc0gSGoGQVIzCJKaQZDUDIKkZhAkNYMgqRkESc0gSGoGQVIzCJKaQZDUDIKkZhAkNfdU1NZw\n3R3jrucejaflGYKkZhAkNYMgqRkESc0gSGoGQVIbFIQktyZ5KsmTSe5P8taxBpO0+dYdhCQ7gU8B\nS1X1HmAbcMNYg0nafENfMmwH3pZkO7ADeHH4SJKmsu4gVNULwBeA54AjwMtV9Z2xBpO0+Ya8ZDgf\nuB64FLgYODfJjac5bm+SlSQrcHz9k0racENeMlwL/KSqjlXVb4EHgPefelBVLVfVUlUtrb6qkDRX\nQ4LwHHBVkh1JAuwBDo0zlqQpDHkP4VHgAHAQ+OFireWR5pI0gUEff66qfcC+kWaRNDGvVJTUDIKk\nZhAkNYMgqbmnoraIV8ZdbuQ9EP+37h51PYB359YRV9u2pqM8Q5DUDIKkZhAkNYMgqRkESc0gSGoG\nQVIzCJKaQZDUDIKkZhAkNYMgqRkESc0gSGoGQVIzCJKaQZDUDIKkZhAkNYMgqbnJqjSCd+fm0de8\n4MQ/jLbWy39175qO8wxBUjMIkppBkNQMgqRmECS1swYhyT1JjiZ58qTHLkjycJJnFl/P39gxJW2G\ntZwhfBW47pTHbgceqarLgEcW9yVtcWcNQlX9APjFKQ9fD7z2g817gY+MPJekCaz3PYSLqurI4vZL\nwEUjzSNpQoPfVKyqAupMf55kb5KVJCtwfOjTSdpA6w3Cz5O8C2Dx9eiZDqyq5apaqqol2LHOp5O0\nGdYbhAeBmxa3bwK+Nc44kqa0lh873g/8F3B5ksNJbgY+D/xNkmeAaxf3JW1xZ/20Y1V97Ax/tGfk\nWSRNzCsVJTWDIKkZBEnNIEhqBkFSy+qFhpv0ZMkx4GdrOPRC4P82eJyh5j7j3OeD+c849/lg7TP+\naVW982wHbWoQ1irJyuqVjfM19xnnPh/Mf8a5zwfjz+hLBknNIEhqcw3C8tQDrMHcZ5z7fDD/Gec+\nH4w84yzfQ5A0jbmeIUiagEGQ1AyCpGYQJDWDIKn9P4RKlwknlWh+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d8bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(cm, cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"This is a language detection test.\" is \"en\"\n",
      "The language of \"Ceci est un test de détection de la langue.\" is \"fr\"\n",
      "The language of \"Dies ist ein Test, um die Sprache zu erkennen.\" is \"de\"\n"
     ]
    }
   ],
   "source": [
    "# Predict the result on some short new sentences:\n",
    "sentences = [\n",
    "    u'This is a language detection test.',\n",
    "    u'Ceci est un test de d\\xe9tection de la langue.',\n",
    "    u'Dies ist ein Test, um die Sprache zu erkennen.',\n",
    "]\n",
    "predicted = clf.predict(sentences)\n",
    "\n",
    "for s, p in zip(sentences, predicted):\n",
    "    print(u'The language of \"%s\" is \"%s\"' % (s, dataset.target_names[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
