{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Language Train Model\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to clone the scikit learn if you dont have the doc folder in sklearn folder within your installed packages. Navigate to doc/tutorials/text_analytics/data and run the fetch data in each tutorial you are working on. If running jupyter from skeletons, you would run the following after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_data_folder = '../data/languages/paragraphs'\n",
    "dataset = load_files(languages_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset in training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                          dataset.target, \n",
    "                                                          test_size=0.5, \n",
    "                                                          random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 10,  1,  7,  4,  2,  0,  7,  8,  9,  1,  2,  3,  5,  1,  1,\n",
       "        5,  4,  1,  5,  5,  2,  3,  2,  1,  4,  4,  4,  3, 10,  1,  4,  4,\n",
       "        9,  6,  4,  7,  2,  1,  1,  0,  2,  8,  2,  8,  8,  4,  2,  4,  2,\n",
       "        3,  2,  1,  1,  9,  7,  1,  2,  1,  6,  2,  4,  1,  6,  4,  2,  3,\n",
       "        1,  8, 10,  1, 10, 10,  3,  6,  5, 10,  8, 10,  1,  5,  6,  2,  9,\n",
       "        3,  9, 10,  4, 10, 10,  3,  3,  1,  5,  5,  5,  9,  8,  2, 10,  1,\n",
       "        3,  5,  6,  1,  0,  6,  2,  9, 10,  6,  2,  7,  1,  2,  4,  2,  5,\n",
       "        3,  2,  0,  3,  4,  5,  9,  2,  5,  7,  9,  4, 10,  1,  2,  6,  3,\n",
       "        2,  2,  0,  1,  2,  7,  9,  3, 10,  8,  3,  1,  2,  6,  1,  1,  2,\n",
       "        3,  8,  2, 10,  3,  6,  3,  9, 10,  4,  1,  6,  2,  4,  3,  5,  9,\n",
       "        2,  3,  1,  7,  6,  5,  3,  1,  9,  9,  7,  9,  1,  9,  2,  1,  8,\n",
       "        1,  9, 10,  9,  3,  3,  2, 10, 10,  4,  6,  4, 10, 10,  3,  4,  8,\n",
       "        2,  4,  6,  6,  1,  4,  1,  4,  3,  4,  5,  9,  1,  9,  2,  4,  0,\n",
       "        8,  5,  3,  5,  4, 10,  4,  4,  1,  2,  2,  1,  1,  6,  8,  1,  3,\n",
       "       10,  7,  1,  1,  1,  2,  2,  1, 10,  9,  4,  3,  6,  2,  5,  1,  6,\n",
       "        3,  8,  4,  6,  9,  3,  2,  0,  9,  1,  1,  9,  1,  2,  1,  1,  3,\n",
       "        3,  6,  3,  0,  1,  5,  4,  4,  9,  3,  5,  4,  4,  9,  8,  2,  2,\n",
       "        4,  1,  4,  1,  6, 10,  8,  5,  2,  1,  8, 10,  1,  9,  4,  2,  9,\n",
       "        5, 10,  2,  9,  2,  0, 10,  6,  3,  1,  9,  3,  6, 10,  2,  2,  7,\n",
       "        4,  1,  2,  9,  4,  2,  9,  0,  5,  6,  9,  2,  3,  4,  6,  4,  1,\n",
       "        1,  1,  8,  0,  2,  9,  2,  5, 10,  5,  4,  9,  7,  1,  4,  1,  4,\n",
       "        9,  9,  9,  3,  1,  9,  1,  4,  5,  3,  8,  2,  5,  2,  7,  7,  3,\n",
       "        9,  5,  6,  9,  4,  7,  2,  1,  9,  3,  2, 10,  9,  4,  0,  2, 10,\n",
       "        2,  1,  3,  5,  1,  4,  1,  9,  2,  1, 10,  2,  8,  2,  4,  1,  3,\n",
       "        6,  2,  3,  9,  5,  1,  9,  5,  7,  6,  0,  2,  4, 10,  3,  6,  6,\n",
       "        3,  4, 10,  2,  8,  7,  3,  9,  9,  1,  6,  1,  1,  3, 10,  6,  1,\n",
       "        4,  5,  1,  3,  3,  9,  4,  4,  6,  6,  3,  6,  3,  2,  8,  2,  9,\n",
       "        1,  5,  4,  9,  5, 10,  4,  2,  2,  3,  1,  9,  3,  9,  1,  6,  3,\n",
       "        4,  1,  2,  4,  4,  5,  9,  2,  2,  4,  2,  0,  3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer that splits strings into sequence of 1 to 3\n",
    "# characters instead of word tokens\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (1,3), use_idf=False)\n",
    "hashing_vectorizer = HashingVectorizer(analyzer = 'char_wb', ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer / classifier pipeline using the previous analyzer\n",
    "# the pipeline instance should stored in a variable named clf\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                    ('vec', tfidf_vectorizer),\n",
    "                    ('clf', Perceptron()),\n",
    "                    ])\n",
    "\n",
    "text_clf_h = Pipeline([\n",
    "                    ('vec', hashing_vectorizer),\n",
    "                    ('clf', Perceptron()),\n",
    "                    ])\n",
    "\n",
    "text_clf_MNB = Pipeline([\n",
    "                    ('vec', tfidf_vectorizer),\n",
    "                    ('clf_MNB', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Fit the pipeline on the training set\n",
    "clf = text_clf.fit(docs_train, y_train)\n",
    "clf_MNB = text_clf_MNB.fit(docs_train, y_train)\n",
    "clf_h = text_clf_h.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = text_clf.predict(docs_test)\n",
    "y_predicted_h = text_clf_h.predict(docs_test)\n",
    "y_predicted_MNB = text_clf_MNB.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       0.93      1.00      0.96        13\n",
      "         de       1.00      1.00      1.00        74\n",
      "         en       0.97      1.00      0.99        75\n",
      "         es       1.00      0.97      0.98        62\n",
      "         fr       1.00      1.00      1.00        65\n",
      "         it       1.00      0.98      0.99        45\n",
      "         ja       1.00      1.00      1.00        35\n",
      "         nl       1.00      1.00      1.00        26\n",
      "         pl       0.95      1.00      0.98        21\n",
      "         pt       0.98      0.96      0.97        48\n",
      "         ru       1.00      1.00      1.00        26\n",
      "\n",
      "avg / total       0.99      0.99      0.99       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       0.93      1.00      0.96        13\n",
      "         de       1.00      1.00      1.00        74\n",
      "         en       0.97      1.00      0.99        75\n",
      "         es       1.00      0.97      0.98        62\n",
      "         fr       1.00      0.98      0.99        65\n",
      "         it       0.98      0.98      0.98        45\n",
      "         ja       1.00      1.00      1.00        35\n",
      "         nl       1.00      1.00      1.00        26\n",
      "         pl       0.95      1.00      0.98        21\n",
      "         pt       0.98      0.96      0.97        48\n",
      "         ru       1.00      1.00      1.00        26\n",
      "\n",
      "avg / total       0.99      0.99      0.99       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted_h,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       0.00      0.00      0.00        13\n",
      "         de       0.22      1.00      0.37        74\n",
      "         en       0.76      1.00      0.86        75\n",
      "         es       0.00      0.00      0.00        62\n",
      "         fr       1.00      0.02      0.03        65\n",
      "         it       0.00      0.00      0.00        45\n",
      "         ja       1.00      0.97      0.99        35\n",
      "         nl       0.00      0.00      0.00        26\n",
      "         pl       0.00      0.00      0.00        21\n",
      "         pt       0.00      0.00      0.00        48\n",
      "         ru       1.00      0.96      0.98        26\n",
      "\n",
      "avg / total       0.41      0.43      0.31       490\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/races/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_predicted_MNB,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 74  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 75  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 60  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 65  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 35  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 26  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 21  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  1 46  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 26]]\n"
     ]
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIKn9L5d9lhOkayKhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11263a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(cm, cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"This is a language detection test.\" is \"en\"\n",
      "The language of \"Ceci est un test de détection de la langue.\" is \"fr\"\n",
      "The language of \"Dies ist ein Test, um die Sprache zu erkennen.\" is \"de\"\n"
     ]
    }
   ],
   "source": [
    "# Predict the result on some short new sentences:\n",
    "sentences = [\n",
    "    u'This is a language detection test.',\n",
    "    u'Ceci est un test de d\\xe9tection de la langue.',\n",
    "    u'Dies ist ein Test, um die Sprache zu erkennen.',\n",
    "]\n",
    "predicted = clf.predict(sentences)\n",
    "\n",
    "for s, p in zip(sentences, predicted):\n",
    "    print(u'The language of \"%s\" is \"%s\"' % (s, dataset.target_names[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17890027, -0.19942126,  0.25111606, -0.80110686, -0.19411918,\n",
       "        -1.04400761, -0.28990774, -0.74829956, -0.59437924, -1.28452954,\n",
       "        -0.3098033 ],\n",
       "       [-0.16662951, -0.5005147 , -0.79412449, -0.15032453,  0.4370057 ,\n",
       "        -0.81009121, -0.31489957, -0.5713718 , -0.60959872, -1.37222979,\n",
       "        -0.26185934],\n",
       "       [-0.18896853,  0.25061685, -0.81917083, -1.05646783, -0.18884781,\n",
       "        -1.3669948 , -0.30153788, -0.71351789, -0.50437212, -1.22134267,\n",
       "        -0.27343279]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ar', 'de', 'en', 'es', 'fr', 'it', 'ja', 'nl', 'pl', 'pt', 'ru']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
